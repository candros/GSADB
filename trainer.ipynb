{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11045,
     "status": "ok",
     "timestamp": 1623165097959,
     "user": {
      "displayName": "Xin Luo",
      "photoUrl": "",
      "userId": "06301970496892076570"
     },
     "user_tz": -480
    },
    "id": "9WSJCqaVkjzj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config\n",
    "\n",
    "from utils.img_aug import img_aug\n",
    "from utils.imgShow import imgShow, imsShow\n",
    "from utils.tfrecord_io import parse_image,parse_shape,toPatchPair, image_example\n",
    "from utils.geotif_io import readTiff, writeTiff\n",
    "from utils.path_io import crop_patch\n",
    "\n",
    "from model.seg_model.watnet import watnet\n",
    "from model.seg_model.deeplabv3_plus import deeplabv3_plus\n",
    "from model.seg_model.resunet32 import ResUNet34\n",
    "from model.seg_model.resnet18 import ResNet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LATriqu7Ygmo"
   },
   "source": [
    "## TF Records\n",
    "### _Write the tfrecord data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tra_tfrecord_scene = 'data/tfrecords/train_scene.tfrecords'\n",
    "path_test_tfrecord_scene = 'data/tfrecords/test_scene.tfrecords'\n",
    "tra_scene_paths = sorted(glob.glob('data/train_test_data/train_scene/*.tif'))\n",
    "tra_truth_paths = sorted(glob.glob('data/train_test_data/train_truth/*.tif'))\n",
    "tra_pair_data = list(zip(tra_scene_paths, tra_truth_paths))\n",
    "print('tra_data length:', len(tra_pair_data))\n",
    "test_scene_paths = sorted(glob.glob('data/train_test_data/test_scene/*.tif'))\n",
    "test_truth_paths = sorted(glob.glob('data/train_test_data/test_truth/*.tif'))\n",
    "test_pair_data = list(zip(test_scene_paths, test_truth_paths))\n",
    "print('test_data length:', len(test_pair_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainging data: Write to a `.tfrecords` file.\n",
    "with tf.io.TFRecordWriter(path_tra_tfrecord_scene) as writer:\n",
    "    for path_scene, path_truth in tra_pair_data:\n",
    "        scene,_ = readTiff(path_scene)\n",
    "        truth,_ = readTiff(path_truth)\n",
    "        scene = np.clip(scene/10000,0,1)  \n",
    "        patch, truth = crop_patch(img=scene, truth=truth)        \n",
    "        tf_example = image_example(patch, truth)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        print(path_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data: Write to a `_scene.tfrecords` file.\n",
    "with tf.io.TFRecordWriter(path_test_tfrecord_scene) as writer:\n",
    "    for path_scene, path_truth in test_pair_data:\n",
    "        scene,_ = readTiff(path_scene)\n",
    "        truth,_ = readTiff(path_truth)\n",
    "        scene = np.clip(scene/10000,0,1)\n",
    "        patch, truth = crop_patch(img=scene, truth=truth)        \n",
    "        tf_example = image_example(patch, truth)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        print(path_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LATriqu7Ygmo"
   },
   "source": [
    "## Data loading\n",
    "### _Load and parse the tfrecord data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2112,
     "status": "ok",
     "timestamp": 1623165104668,
     "user": {
      "displayName": "Xin Luo",
      "photoUrl": "",
      "userId": "06301970496892076570"
     },
     "user_tz": -480
    },
    "id": "9V1GtRELzsyY"
   },
   "outputs": [],
   "source": [
    "### data loading from .tfrecord file\n",
    "path_train_data_scene = r'data\\tfrecords\\train_scene.tfrecords'\n",
    "path_test_data_scene = r'data\\tfrecords\\test_scene.tfrecords'\n",
    "\n",
    "## training data\n",
    "tra_dset = tf.data.TFRecordDataset(path_train_data_scene) \n",
    "\n",
    "tra_dset = tra_dset.map(parse_image).map(parse_shape)\\\n",
    "            .cache()\\\n",
    "            .map(toPatchPair)\\\n",
    "            .map(img_aug)\n",
    "tra_dset = tra_dset.shuffle(config.buffer_size).batch(config.batch_size)\n",
    "\n",
    "## Test data\n",
    "test_dset = tf.data.TFRecordDataset(path_test_data_scene)\n",
    "test_dset = test_dset.map(parse_image).map(parse_shape)\\\n",
    "            .map(toPatchPair)\\\n",
    "            .cache()\n",
    "\n",
    "test_batch = 8\n",
    "test_dset = test_dset.batch(test_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 36635,
     "status": "ok",
     "timestamp": 1623165142400,
     "user": {
      "displayName": "Xin Luo",
      "photoUrl": "",
      "userId": "06301970496892076570"
     },
     "user_tz": -480
    },
    "id": "yUNLuDPEnObz",
    "outputId": "5c37cea7-6c83-4c59-c935-a680642bc5b7"
   },
   "outputs": [],
   "source": [
    "## check\n",
    "# for i in range(5):\n",
    "start = time.time()\n",
    "i_batch = i_scene = 0\n",
    "for patch, truth in tra_dset:\n",
    "    i_batch += 1\n",
    "    i_scene += patch.shape[0]\n",
    "imsShow(img_list=[patch[0], truth[0]], \n",
    "        img_name_list=['patch', 'truth'],\n",
    "        clip_list=[2,0])\n",
    "\n",
    "plt.show()\n",
    "print('number of batches:', i_batch)\n",
    "print('num of scenes:', i_scene)\n",
    "print('time:', time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check\n",
    "# for i in range(5):\n",
    "start = time.time()\n",
    "i_batch = i_scene = 0\n",
    "for patch, truth in test_dset:\n",
    "    i_batch += 1\n",
    "    i_scene += patch.shape[0]\n",
    "imsShow(img_list=[patch[0], truth[0]], \n",
    "        img_name_list=['patch', 'truth'],\n",
    "        clip_list=[2,0])\n",
    "\n",
    "plt.show()\n",
    "print('number of batches:', i_batch)\n",
    "print('num of scenes:', i_scene)\n",
    "print('time:', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1623158088864,
     "user": {
      "displayName": "Xin Luo",
      "photoUrl": "",
      "userId": "06301970496892076570"
     },
     "user_tz": -480
    },
    "id": "Z_tRRKoBkrSK",
    "outputId": "609ff8d3-69b7-47e5-93ff-17eea2a84e05"
   },
   "outputs": [],
   "source": [
    "## model configuration\n",
    "#model = watnet(input_shape=(config.patch_size, config.patch_size, config.num_bands), nclasses=2)\n",
    "#model = deeplabv3_plus(nclasses=2, input_shape=(config.patch_size, config.patch_size, config.num_bands))\n",
    "#model = ResUNet34(input_shape=(config.patch_size, config.patch_size, config.num_bands))\n",
    "model = ResNet18(input_shape=(config.patch_size, config.patch_size, config.num_bands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1623158088866,
     "user": {
      "displayName": "Xin Luo",
      "photoUrl": "",
      "userId": "06301970496892076570"
     },
     "user_tz": -480
    },
    "id": "7DuKTA6Fr5eL"
   },
   "outputs": [],
   "source": [
    "'''------1. train step------'''\n",
    "@tf.function\n",
    "def train_step(model, loss_fun, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pre = model(x, training=True)\n",
    "        loss = loss_fun(y, y_pre)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    #grad_norms = [tf.norm(g) for g in grads if g is not None]\n",
    "    #tf.print(\"Gradient norms:\",tf.reduce_max(grad_norms), tf.reduce_min(grad_norms))\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    config.tra_loss.update_state(loss)\n",
    "    config.tra_oa.update_state(y, y_pre)\n",
    "    config.tra_miou.update_state(y, y_pre)\n",
    "    return config.tra_loss.result(), config.tra_oa.result(), config.tra_miou.result()\n",
    "\n",
    "'''------2. test step------'''\n",
    "@tf.function\n",
    "def test_step(model, loss_fun, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pre = model(x, training=False)\n",
    "        loss = loss_fun(y, y_pre)\n",
    "    config.test_loss.update_state(loss) \n",
    "    config.test_oa.update_state(y, y_pre)\n",
    "    config.test_miou.update_state(y, y_pre)\n",
    "    return config.test_loss.result(), config.test_oa.result(), config.test_miou.result()\n",
    "\n",
    "'''------3. train loops------'''\n",
    "def train_loops(model, loss_fun, optimizer, tra_dset, test_dset, epochs, output):\n",
    "\n",
    "    # Initialize the outputs\n",
    "    test_miou, test_loss, test_oa, tra_miou, tra_loss, tra_oa = [], [], [], [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        ###--- train the model ---\n",
    "        for x_batch, y_batch in tra_dset:\n",
    "            tra_loss_epoch, tra_oa_epoch,tra_miou_epoch = train_step(model, loss_fun, optimizer, x_batch, y_batch)\n",
    "        ### --- test the model ---\n",
    "        for x_batch, y_batch in test_dset:\n",
    "            test_loss_epoch, test_oa_epoch, test_miou_epoch = test_step(model, loss_fun, x_batch, y_batch)\n",
    "        ### --- update the metrics ---\n",
    "        config.tra_loss.reset_states(), config.tra_oa.reset_states(), config.tra_miou.reset_states()\n",
    "        config.test_loss.reset_states(), config.test_oa.reset_states(), config.test_miou.reset_states()\n",
    "        format = 'Ep {}/{}: traLoss:{:.3f},traOA:{:.3f},traMIoU:{:.3f},testLoss:{:.3f},testOA:{:.3f},testMIoU:{:.3f},time:{:.1f}s'\n",
    "        print(format.format(epoch + 1, config.epochs, tra_loss_epoch, tra_oa_epoch, tra_miou_epoch, test_loss_epoch, test_oa_epoch, test_miou_epoch, time.time() - start))\n",
    "        test_miou.append(test_miou_epoch.numpy())\n",
    "        test_loss.append(test_loss_epoch.numpy())\n",
    "        test_oa.append(test_oa_epoch.numpy())\n",
    "        tra_miou.append(tra_miou_epoch.numpy())\n",
    "        tra_loss.append(tra_loss_epoch.numpy())\n",
    "        tra_oa.append(tra_oa_epoch.numpy())\n",
    "\n",
    "        # Save the final iteration\n",
    "        if (epoch+1)%config.epochs == 0:\n",
    "            path_save = 'model/pretrained/'+output+'.h5py'\n",
    "            model.save(path_save) \n",
    "            metric_path = 'results/metrics_'+output+'.csv'\n",
    "            dataframe = pd.DataFrame({'test_miou':test_miou, 'test_oa':test_oa, 'test_loss':test_loss, 'tra_miou':tra_miou, 'tra_oa':tra_oa, 'tra_loss':tra_loss})\n",
    "            dataframe.to_csv(metric_path, index=False, sep=',')\n",
    "            \n",
    "        ## --- visualize the results ---\n",
    "        if epoch%10 == 0:\n",
    "            i = np.random.randint(test_batch)\n",
    "            for test_patch, test_truth in test_dset.take(1):\n",
    "                plt.figure(figsize=(10,4))\n",
    "                pre = model(test_patch, training=False)\n",
    "                imsShow(img_list=[test_patch.numpy()[i], test_truth.numpy()[i], pre.numpy()[i]], \\\n",
    "                        img_name_list=['test_patch', 'test_truth', 'prediction'], \\\n",
    "                        clip_list=[2,0,0],\\\n",
    "                        color_bands_list=None)\n",
    "                plt.show()\n",
    "    \n",
    "    return test_miou, test_loss, test_oa, tra_miou, tra_loss, tra_oa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IveYVICCr5eM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model training\n",
    "with tf.device('/device:GPU:1'):\n",
    "   test_miou, test_loss, test_oa, tra_miou, tra_loss, tra_oa = train_loops(model=model, \\\n",
    "                        loss_fun=config.loss_dice, \\\n",
    "                        #loss_fun=config.loss_focal, \\\n",
    "                        #loss_fun = config.loss_focal_dice, \\\n",
    "                        #loss_fun = config.loss_bce_dice, \\\n",
    "                        #loss_fun = config.loss_bce, \\\n",
    "                        optimizer=config.opt_adam, \\\n",
    "                        tra_dset=tra_dset, \\\n",
    "                        test_dset=test_dset, \\\n",
    "                        epochs=config.epochs,\n",
    "                       output = 'test_resnet_dice'\n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainer.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "540331ab3874cc423b0568d77e5ba6321eb807f34352bd2dfeeaef70fdba3ae8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "metadata": {
   "interpreter": {
    "hash": "540331ab3874cc423b0568d77e5ba6321eb807f34352bd2dfeeaef70fdba3ae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
